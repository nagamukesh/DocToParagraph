{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Warm up !"
      ],
      "metadata": {
        "id": "srbcNGTRhoF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfqZSfP-Raaq"
      },
      "outputs": [],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph=\"\"\"\n",
        "India, officially the Republic of India (ISO: Bhārat Gaṇarājya),[21] is a country in South Asia. It is the seventh-largest country by area; the most populous country as of June 2023;[22][23] and from the time of its independence in 1947, the world's most populous democracy.[24][25][26] Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west;[j] China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand, Myanmar, and Indonesia.\n",
        "\n",
        "Modern humans arrived on the Indian subcontinent from Africa no later than 55,000 years ago.[27][28][29] Their long occupation, initially in varying forms of isolation as hunter-gatherers, has made the region highly diverse, second only to Africa in human genetic diversity.[30] Settled life emerged on the subcontinent in the western margins of the Indus river basin 9,000 years ago, evolving gradually into the Indus Valley Civilisation of the third millennium BCE.[31] By 1200 BCE, an archaic form of Sanskrit, an Indo-European language, had diffused into India from the northwest.[32][33] Its evidence today is found in the hymns of the Rigveda. Preserved by an oral tradition that was resolutely vigilant, the Rigveda records the dawning of Hinduism in India.[34] The Dravidian languages of India were supplanted in the northern and western regions.[35] By 400 BCE, stratification and exclusion by caste had emerged within Hinduism,[36] and Buddhism and Jainism had arisen, proclaiming social orders unlinked to heredity.[37] Early political consolidations gave rise to the loose-knit Maurya and Gupta Empires based in the Ganges Basin.[38] Their collective era was suffused with wide-ranging creativity,[39] but also marked by the declining status of women,[40] and the incorporation of untouchability into an organised system of belief.[k][41] In South India, the Middle kingdoms exported Dravidian-languages scripts and religious cultures to the kingdoms of Southeast Asia.[42]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mqDaxR7qR2EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph"
      ],
      "metadata": {
        "id": "K7LY9qRYSNAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "O6AwfslvSXwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "Cllwx3UlSdxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')##for tokenizing\n",
        "sentences=nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "TUbpO1S4SjYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "id": "H8ntv85xS8VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()\n",
        "stemmer.stem('thinking')##stemming!"
      ],
      "metadata": {
        "id": "DxHAHUnjTX2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()\n",
        "lemmatizer.lemmatize('goes')##not so efficient as it focuses on spellings!"
      ],
      "metadata": {
        "id": "u2vdpxtHTijq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re #regular expressions\n",
        "\n",
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "  review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
        "  review=review.lower()\n",
        "  corpus.append(review)"
      ],
      "metadata": {
        "id": "GjXvscu_UIhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "xL7QMCRCU7YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## stemming:\n",
        "nltk.download('stopwords')\n",
        "for i in corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(stemmer.stem(word))"
      ],
      "metadata": {
        "id": "de02DJiYVH1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(binary=True)##binary bag of words\n"
      ],
      "metadata": {
        "id": "UEVU7wL1Vszy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=cv.fit_transform(corpus)"
      ],
      "metadata": {
        "id": "mMc7-c-TWGTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_##gives the words in bad of words"
      ],
      "metadata": {
        "id": "8jZ_wSeDWOew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "id": "U6OYEJxSWV6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].toarray()"
      ],
      "metadata": {
        "id": "k2S16LBYWYKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "matrix=pd.DataFrame(X.toarray(),columns=cv.get_feature_names_out())"
      ],
      "metadata": {
        "id": "8K11rwNWXDq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix"
      ],
      "metadata": {
        "id": "o3GU6WpKhWcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "SsyhaPKXhhkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Actual task**"
      ],
      "metadata": {
        "id": "T1C9TKs0hvFV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normal vectorization using binary bag of words"
      ],
      "metadata": {
        "id": "5QGilnjIp-nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/spam.csv',encoding='latin-1')"
      ],
      "metadata": {
        "id": "0K40zU1uiUW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "Z7gdKvvSiafq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new=df.iloc[:,0:2]"
      ],
      "metadata": {
        "id": "Bu1_vK8Zi1y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.head(1)"
      ],
      "metadata": {
        "id": "ngQqTQWLjFYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.rename(columns={'v1':'target','v2':'text'},inplace=True)"
      ],
      "metadata": {
        "id": "Dis6z89NjWYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new.head()"
      ],
      "metadata": {
        "id": "AScDbs8wjg9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data=df_new.iloc[:,0]"
      ],
      "metadata": {
        "id": "TYoKlg_kjm_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_data.shape"
      ],
      "metadata": {
        "id": "DhBM6I-djxvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_corpus=df_new.iloc[:,1]\n",
        "input_corpus.isna().sum()\n",
        "input_corpus.shape"
      ],
      "metadata": {
        "id": "xg1FRxmDkKdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_corpus.head(1)"
      ],
      "metadata": {
        "id": "ZGyyrRIokR5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(input_corpus)):\n",
        "  input_corpus[i]=re.sub('[^a-zA-Z]',' ',input_corpus[i]) ##taking regular expression"
      ],
      "metadata": {
        "id": "NLKn4mu4lP8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_corpus[0]"
      ],
      "metadata": {
        "id": "3v4CU7mMlU7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in input_corpus:\n",
        "  words=nltk.word_tokenize(i)\n",
        "  for word in words:\n",
        "    if word not in set(stopwords.words('english')):\n",
        "      print(stemmer.stem(word))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jKbegpJ9lc0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv=CountVectorizer(binary=True)##binary bag of words"
      ],
      "metadata": {
        "id": "byrj8UvomEBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=cv.fit_transform(input_corpus)"
      ],
      "metadata": {
        "id": "aPws6rgel7lN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv.vocabulary_"
      ],
      "metadata": {
        "id": "9GrYCVgXm2q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "9BOIGVs2m51i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].shape"
      ],
      "metadata": {
        "id": "c-_60s0qm91s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix=pd.DataFrame(X.toarray(),columns=cv.get_feature_names_out())\n",
        "matrix.head()"
      ],
      "metadata": {
        "id": "bAE2c9FUnPgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.sum()## not everything is zero"
      ],
      "metadata": {
        "id": "we6rktAvngQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y=target_data\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "uqHiUPHsnkXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create a LabelEncoder object\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit the encoder on the unique values in Y_train\n",
        "le.fit(np.unique(Y))\n",
        "\n",
        "# Transform the Y_train data using the encoder\n",
        "Y_encoded = le.transform(Y)"
      ],
      "metadata": {
        "id": "OKtHOf51s7P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the sparse matrix to a dense matrix\n",
        "dense_matrix = X.toarray()\n",
        "\n",
        "# Check for missing values in the dense matrix\n",
        "missing_values = pd.isnull(dense_matrix).sum()\n",
        "\n",
        "# Print the number of missing values in each column\n",
        "print(missing_values)"
      ],
      "metadata": {
        "id": "xxghbkrzsHfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(X,Y_encoded,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "zntXBUN3n1Se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
      ],
      "metadata": {
        "id": "SEQokbTqoApv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier=MultinomialNB()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "Iu8UAQ2on9EK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier=DecisionTreeClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "lxebUdzAoX2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "liZ9sz6CoaqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier=LogisticRegression()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "utpApb_2ode2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier=SVC()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "ZuHcC-Dxoh27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier=KNeighborsClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "MmA3y8groqKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "id": "-_0LyxVfo3AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "classifier=XGBClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "zygIgQ2Qos2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tfidf and stuff!"
      ],
      "metadata": {
        "id": "ybEvKdhGtW4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf=TfidfVectorizer()"
      ],
      "metadata": {
        "id": "AL5X-7Oqtafg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_corpus=tfidf.fit_transform(input_corpus)\n",
        "tfidf.vocabulary_\n"
      ],
      "metadata": {
        "id": "tY5c6ljdxNhF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modified_corpus.toarray()[:2].sum()##not all are zeros!"
      ],
      "metadata": {
        "id": "NW-OPPB5xk-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,Y_train,Y_test=train_test_split(modified_corpus,Y_encoded,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "LatA_CJExvZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
      ],
      "metadata": {
        "id": "LUWtAAUsyUTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier=MultinomialNB()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "lMZjLHuMyVs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "classifier=DecisionTreeClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "tvY8pkLOyYA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier=RandomForestClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "yG6MdUneyZcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier=LogisticRegression()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "VIaE48sCybMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier=SVC()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "V2SszYQVyclJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier=KNeighborsClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "mGHOmZa3ygv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "classifier=XGBClassifier()\n",
        "classifier.fit(X_train,Y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "acc=accuracy_score(Y_test,y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "7NK7qa_1yiNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec"
      ],
      "metadata": {
        "id": "tZgV7P9Py3rI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "IbqnKPRHy8-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "qHbyoj3wJKTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=gensim.models.Word2Vec(sentences=sentences,window=5,min_count=1,workers=4)"
      ],
      "metadata": {
        "id": "kkM2bPLvJPWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(input_corpus,update=True)"
      ],
      "metadata": {
        "id": "YXklr22UJX7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train(input_corpus,total_examples=model.corpus_count,epochs=model.epochs)"
      ],
      "metadata": {
        "id": "vm_y9LSOJtGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.get_normed_vectors()"
      ],
      "metadata": {
        "id": "zeYMc0PQJz7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=model.wv.index_to_key"
      ],
      "metadata": {
        "id": "q5l-4dFbKTzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "id": "wbyKEDXiKcdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "iAsEEGY1Kefe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(input_corpus)\n",
        "tfidf_weights = X.toarray()"
      ],
      "metadata": {
        "id": "kEv3xqPWLGkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_word_vectors = []\n",
        "for text, tfidf_weight in zip(input_corpus, tfidf_weights):\n",
        "    doc_vector = np.zeros(100)\n",
        "    weight_sum = 0\n",
        "    for word, weight in zip(text.split(), tfidf_weight):\n",
        "        if word in model.wv:\n",
        "            doc_vector += model.wv[word] * weight\n",
        "            weight_sum += weight\n",
        "    if weight_sum != 0:\n",
        "        doc_vector /= weight_sum\n",
        "    tfidf_word_vectors.append(doc_vector)\n"
      ],
      "metadata": {
        "id": "bY3GQJoFLLjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "DRMlwYs4LbEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(tfidf_word_vectors, Y_train)"
      ],
      "metadata": {
        "id": "S92eu2maLUW8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}